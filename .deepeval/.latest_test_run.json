{"testRunData": {"testFile": "test_qwen_eval.py", "testCases": [{"name": "test_qwen_answer_relevancy", "input": "What is the capital of France?", "actualOutput": "The capital of France is Paris.", "expectedOutput": "Paris", "success": true, "metricsData": [{"name": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the output is fully relevant and directly addresses the question about the capital of France without any irrelevant statements.", "strictMode": false, "evaluationModel": "Qwen3-235B-A22B-2507 (Bedrock Judge)", "verboseLogs": "Statements:\n[\n    \"The capital of France is Paris.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"}], "runDuration": 1.4525733750197105, "order": 0}], "conversationalTestCases": [], "metricsScores": [{"metric": "Answer Relevancy", "scores": [1.0], "passes": 1, "fails": 0, "errors": 0}], "testPassed": 1, "testFailed": 0, "runDuration": 2.251630375016248}}